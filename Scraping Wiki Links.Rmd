---
title: "Scraping Wikipedia Links"
author: "Rohan Khollamkar"
date: "19 April 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**Load Libraries**
```{r libraries, echo=T}
library(rvest)

library(stringr)
```
**Read Wikipedia Page**
```{r read_page,echo=T}
sourceggl <- "https://en.wikipedia.org/wiki/Artificial_intelligence"
PageText <- read_html(sourceggl) 
print(PageText)
```

**Get any 25 links and Loop Over it**
```{r get_links,echo =T}
links <- PageText%>%
         html_nodes('a')%>%
         html_attr('href')
print(links[7:32])


Total.Links <- c()
for (i in links[7:32]){
  newLink <- str_remove(paste("https://en.wikipedia.org",i)," ")
  PageText <- read_html(newLink)
  PageLinks <- PageText%>%html_nodes('i > a')%>%html_attr('href')
  Total.Links <-  c(Total.Links,paste("https://en.wikipedia.org",PageLinks))
}
print(Total.Links)

```






















































































